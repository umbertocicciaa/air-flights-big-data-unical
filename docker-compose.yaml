services:
    namenode:
        image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
        container_name: namenode
        restart: always
        volumes:
            - hadoop_namenode:/hadoop/dfs/name
        environment:
            - CLUSTER_NAME=test
        ports:
            - 9870:9870
            - 8020:8020
            - 9000:9000
        networks:
            - hadoop
        env_file:
            - hadoop.env

    datanode:
        image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
        container_name: datanode
        restart: always
        depends_on: 
            - namenode
        volumes:
            - hadoop_datanode:/hadoop/dfs/data
        environment:
            SERVICE_PRECONDITION: "namenode:9870"
        ports:
            - 9864:9864
        env_file:
            - hadoop.env
        networks:
            - hadoop

    spark-master:
        image: bde2020/spark-master:3.3.0-hadoop3.3
        container_name: spark-master
        depends_on:
            - namenode
            - datanode
        environment:
            - INIT_DAEMON_STEP=setup_spark
        ports:
            - 8080:8080
            - 7077:7077
        networks:
            - hadoop

    spark-worker-1:
        image: bde2020/spark-worker:3.3.0-hadoop3.3
        container_name: spark-worker-1
        depends_on:
            - spark-master
        ports:
            - "8081:8081"
        environment:
            - "SPARK_MASTER=spark://spark-master:7077"
        networks:
             - hadoop

volumes:
    hadoop_namenode:
    hadoop_datanode:
    
networks:
    hadoop:
        name: hadoop