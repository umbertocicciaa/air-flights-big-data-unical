services:
    namenode:
        image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
        container_name: namenode
        restart: always
        volumes:
            - hadoop_namenode:/hadoop/dfs/name
        environment:
            - CLUSTER_NAME=test
        ports:
            - 9870:9870
            - 8020:8020
            - 9000:9000
        networks:
            - hadoop
        env_file:
            - hadoop.env

    datanode:
        image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
        container_name: datanode
        restart: always
        depends_on: 
            - namenode
        volumes:
            - hadoop_datanode:/hadoop/dfs/data
        environment:
            SERVICE_PRECONDITION: "namenode:9870"
        ports:
            - 9864:9864
        env_file:
            - hadoop.env
        networks:
            - hadoop

    spark-master:
        image: docker.io/bitnami/spark:3.5
        container_name: spark-master
        depends_on:
            - namenode
            - datanode
        environment:
            - INIT_DAEMON_STEP=setup_spark
            - SPARK_MODE=master
        ports:
            - 8080:8080
            - 7077:7077
            - 6066:6066
        networks:
            - hadoop

    spark-worker-1:
        image: docker.io/bitnami/spark:3.5
        container_name: spark-worker-1
        depends_on:
            - spark-master
        ports:
            - "8081:8081"
        environment:
            - SPARK_MASTER=spark://spark-master:7077
            - SPARK_MODE=worker
            - SPARK_WORKER_WEBUI_PORT=8081
        networks:
            - hadoop

    app:
        build:
            context: ./src/
            dockerfile: Dockerfile
        container_name: app
        restart: always
        depends_on:
            - spark-master
            - spark-worker-1
            - namenode
            - datanode
            - redis
        env_file:
            - src/dev.env
        networks:
            - hadoop
        ports:
            - 8501:8501
        volumes:
            - ./shared-filesystem:/mnt/shared-filesystem:rw
    
    redis:
        image: redis:7.4.4-alpine3.21
        restart: always
        ports:
            - 6379:6379
        networks:
            - hadoop

    hive-server:
        image: bde2020/hive:2.3.2-postgresql-metastore
        container_name: hive-server
        depends_on:
            - namenode
            - datanode
        env_file:
            - ./hadoop-hive.env
        environment:
            HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
            SERVICE_PRECONDITION: "hive-metastore:9083"
        ports:
            - "10000:10000"
        networks:
            - hadoop

    hive-metastore:
        image: bde2020/hive:2.3.2-postgresql-metastore
        container_name: hive-metastore
        env_file:
            - ./hadoop-hive.env
        command: /opt/hive/bin/hive --service metastore
        environment:
            SERVICE_PRECONDITION: "namenode:9870 datanode:9864 hive-metastore-postgresql:5432"
        ports:
            - "9083:9083"
        networks:
            - hadoop

    hive-metastore-postgresql:
        image: bde2020/hive-metastore-postgresql:2.3.0
        container_name: hive-metastore-postgresql
        ports:
            - "5433:5432"
        networks:
            - hadoop

    presto-coordinator:
        image: shawnzhu/prestodb:0.181
        container_name: presto-coordinator
        ports:
        - "8089:8089"

volumes:
    hadoop_namenode:
    hadoop_datanode:
    
networks:
    hadoop:
        name: hadoop